# Apache Kafka
Apache Kafka is a **Distributed Stream Processing System**. This uses to publish and subscribe mechanism to stream the records. It is originally developed by **LinkedIn** to handle their log files and later, handed over to the open-source community in early 2011. It became the main Apache project in October 2012. A stable Apache Kafka version 0.8.2.0 was released in Feb 2015. The latest version 2.3.0 was released on April 9, 2021. Currently used by many big enterprises like Netflix, Uber and Walmart.
## What is Streaming Data
Streaming  data is data that is continuously generated by thousands of data sources which typically send the data records in simultaneously. A streaming platform needs to handle this constant influx of data and process the data sequentially and incrementally.
## The key features of Kafka
- It is a distributed and partitioned messaging system.
- It is highly fault-tolerant.
- It is highly scalable.
- It can process and send millions of messages per second to several receivers.

## Kafka use cases
Kafka can be useful for various purposes in an organization, such as:
- **Messaging Service**: Millions of messages can be sent and recieved in real life using Kafka.
- **Real-time Stream Processing**: Kafka can be used to process a continuous stream of information in real-time and pass it to stream processing systems such as **Storm**. 
- **Log aggregation**: Kafka can be used to collect physical log files from multiple systems and store them in a central location such as ***HDFS***.
- **Commit log Service**: Kafka can be used as an external commit log for distribution systems. 
## Aggregating User Activity Using Kafka
 ### Example :
 Kafka can be used to aggregate user activity data such as clicks, navigation, and searches from different websites of an organization; such user activities can be sent to the real-time monitoring system and Hadoop  system for offline processing.
 [KafkaCluster](https://www.flickr.com/photos/195655839@N07/52083551805/in/dateposted-public/)
 ## Kafka Data Model
The Kafka  data model consists of messages and topics.
- Messaging represents information such as a line in a log file, a row of stock market data, or an error message from the system.
- Messages are grouped into categories called topics. Example: LogMessage and StockMessage.
- The process that publishes messages into a topic in Kafka is known as producers.
- The process that receives the message from a topic in Kafka is known as consumers.
- The processes or servers within Kafka that process the message are known as brokers.
- A Kafka cluster consists of a set of brokers that process the messages.
## Topics
A topic is a category of messages in Kafka
- The producers publish the message into topics.
- The consumers read the messages from topics.
- A topic is divided into one or more partitions.
- A partition is also known as a commit log.
- Each partition contains an ordered set of messages.
- Each message is identified by its offset in the partition.
- Messages are added at one end of the partition and consumed at the other.
# References
- [YouTubeKafkaTutorial](https://www.youtube.com/watch?v=U4y2R3v9tlY).
- [WhatisApacheKafka](https://aws.amazon.com/msk/what-is-kafka/)
