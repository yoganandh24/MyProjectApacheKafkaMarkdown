# Apache Kafka
Apache Kafka is a **Distributed Stream Processing Sysyem**. This uses publish and subscribe mechanism to stream the records. It is originally developed by **LinkedIn** to handle their log files and later, handed over to the open source community in early 2011. It became a main Apache project in October, 2012. A stable Apache Kafka version 0.8.2.0 was released in Feb, 2015 . The latest version 2.3.0 was released in April 9 2021. Currently used by many big enterprises like Netflix,uber,Walmart.
## What is Streaming Data
Streaming  data is data that is continuously generated by thousands of data sources which typycally send the data records in simultaniously. A streaming platform needs to handle this constant influx of data and process the data sequentially and incrementally.
## The key features of Kafka
- It is a distributed and partitioned messaging system.
- It is highly fault-tolerant.
- It is highly scalable.
- It can process and send millions of messages per second to several recievers.

## Kafka use cases
Kafka can be useful for various purposes in an Organization, such as:
- **Messaging Service** : Millions of messages can be sent and recieved in real-life, using Kafka.
- **Real-time Stream Processing** : Kafka can be used to process a continuous stream of information in real-time and pass it to stream processing systems such as **Storm**. 
- **Log agregation** : Kafka can be used to collect physical log files from multiple systems and store them in a central location such as ***HDFS***.
- **Commit log Service** : Kafka can be used as an external commit log for distribute systems. 
## Aggregating User Activity Using Kafka
 ### Example :
 Kafka can be used to aggregate user activity data such as clicks, navigation, and searches from different websites of an organization; such user activities can be sent to real-time monitoring system and handoop system for offline processing.
 [KafkaCluster](https://www.flickr.com/photos/195655839@N07/52083551805/in/dateposted-public/)
 ## Kafka Data Model
The Kafka  data model consists of messages and topics.
- Messaging represents information such as, line in a log file, a row of stock market data, or an error message from system.
- Message are grouped into categories called topics. Example: LogMessage and StockMessage.
- The process that publish message into a topic in kafka are known as producers.
- The process that recieve the message from a topic in Kafka are known as consumers.
- The processes or servers within Kafka that process the message are known as brokers.
- A Kafka cluster consists of a set of brokers that process the messages.
## Topics
A topic is a category of messages in Kafka
- The producers publish the message into topics.
- The consumers read the messages from topics.
- A topic is divided into one or more partitions.
- A partition is also known as vommit log.
- Each partition contains an ordered set of messages.
- Each message is identified by its offset in the partition.
- Messages are added at one end of the partition and consumed at the other.
# References
- [YouTubeKafkaTutorial](https://www.youtube.com/watch?v=U4y2R3v9tlY).
- [WhatisApacheKafka](https://aws.amazon.com/msk/what-is-kafka/)
